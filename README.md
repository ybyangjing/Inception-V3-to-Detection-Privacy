# Inception-V3-to-Detection-Privacy
Recent research has shown that the ubiquitous use of cameras and voice monitoring equipment in a home environment raises privacy concerns and affects human mental health, even causing mental disorders. This condition is a major obstacle to the deployment of smart home systems for elderly or disabled care. The current study uses a social robot for privacy situation detection. When a privacy situation is detected, the robot turns the camera away from the users and stores the abstract information in a text file. we proposed a method of detection of privacy situations based on Convolution Neural Network for Social Robot (DPS-SR). Firstly, this paper designed a questionnaire aiming at the privacy protection and social robot, and then analysed the focused factors and its attention degree of people that related to the privacy information caused by using social robot. Then designed a algorithm to detect the privacy situations based on Convolution Neural Network, and then the hardware platform of social robot and the overall workflow were detailed, and then implemented the complete system of DPS-SR. If the robot system detects a privacy situation, it will turn around and store the abstracted information to text file. Considering the results of the questionnaire survey, six classes of home situations were designed, and the training data sets for deep feature extraction about those situations were collected, which includes 2580 pictures. In order to check the performance of proposed system, we designed three experiment and four different testing datasets, which involves 960 pictures. The testing results shows as follows:1) when the testing dataset and the training dataset share the same home environment, the situation recognition accuracy of the proposed system is distributed from 97.5% to 100%, which indicates that the change of people has little effect on the situation recognition accuracy. 2) When the testing dataset and the training dataset include the same people, the system put out the recognition accuracy between 85% and 95%. 3) When the people and the home environment are changed between the testing dataset and training dataset, the systemâ€™s situation recognition accuracy is distributed in 80%~97.5%. The proposed system report an average recognition accuracy of 94.69%, which indicates the systems has reasonable robustness.
